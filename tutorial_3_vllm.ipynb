{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c09c1436-a82c-4c2a-814d-63840b959898",
   "metadata": {},
   "source": [
    "# Vllm\n",
    "\n",
    "<center>\n",
    "<img src=\"https://docs.vllm.ai/en/stable/assets/logos/vllm-logo-text-light.png\" alt=\"vllm logo\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "Vllm is less cool and has an ugly logo :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa73c86-e700-4284-91f1-fd11ebdc1d8e",
   "metadata": {},
   "source": [
    "### ðŸ³ï¸ Open the cc-in2p3 Jupyter Notebook launcher at \n",
    "\n",
    "> `https://notebook.cc.in2p3.fr`\n",
    "\n",
    "\n",
    "launch a new terminal session\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://icon-library.com/images/bash-icon/bash-icon-6.jpg\" alt=\"bash is also cool\" width=\"200\"/>\n",
    "</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b631187b-0a99-48b5-b55e-8aed1df727f0",
   "metadata": {},
   "source": [
    "and execute therein the following commands to load the previously prepared enviroment with vllm installed\n",
    "\n",
    "```bash\n",
    "# Set up Modules\n",
    "source /etc/profile.d/modules.sh\n",
    "module purge\n",
    "module load Programming_Languages/python/3.11.4\n",
    "\n",
    "# Activate conda environment\n",
    "source /pbs/throng/training/universite-hiver/wschooloptim/vllm/bin/activate\n",
    "\n",
    "# Enforce correct site-packages\n",
    "unset PYTHONPATH\n",
    "export PYTHONPATH=/pbs/throng/training/universite-hiver/wschooloptim/vllm/lib/python3.11/site-packages/\n",
    "\n",
    "# Ollama and HF cache setting\n",
    "export HUGGINGFACE_HUB_CACHE=/pbs/throng/training/universite-hiver/cache/huggingface\n",
    "export OLLAMA_MODELS=/pbs/throng/training/universite-hiver/cache/ollama/models\n",
    "```\n",
    "\n",
    "launch an vllm server\n",
    "\n",
    "```bash\n",
    "vllm serve HuggingFaceH4/zephyr-7b-beta --max_model_len=10000 --guided_decoding_backend=xgrammar --seed=1  --tensor-parallel-size 1 &\n",
    "```\n",
    "\n",
    "Create one request to ollama's server:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:8000/v1/chat/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "  \"model\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "  \"messages\": [{ \"role\": \"user\", \"content\": \"Who won the last presidential elections in France?\" }]\n",
    "}'\n",
    "```\n",
    "\n",
    "Keep that terminal open for the rest of the tutorial, we will check therein ollama server logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317ec75-d0a9-4316-b7b2-b304a525c78d",
   "metadata": {},
   "source": [
    "### ðŸ´ Open another cc-in2p3 Jupyter Notebook launcher at \n",
    "\n",
    "> `https://notebook.cc.in2p3.fr`\n",
    "\n",
    "\n",
    "and launch now the Notebook called `Python 3.13 (Ollama)`.\n",
    "\n",
    "We will work from now in that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ff749-027b-46ac-b277-073328f88af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! xan tail /pbs/home/u/univ-hiver01/private/resinwinterschool/tweets_spanish_english_25K.csv | /pbs/throng/training/universite-hiver/wschooloptim/vllm/bin/xan v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b6181-35c7-4cbd-872a-d33c9a6b6f48",
   "metadata": {},
   "source": [
    "##### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27085d2a-86af-438e-939b-0887477cf9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import asyncio\n",
    "from openai import OpenAI\n",
    "from string import Template\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f2b07-a4e3-4e51-884a-67241aea0aa3",
   "metadata": {},
   "source": [
    "##### Load inputs and create asynchronous iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9237dfb-bb1e-4ee5-84b6-823ddac08a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/pbs/home/u/univ-hiver01/private/resinwinterschool/tweets_spanish_english_25K.csv\"\n",
    "content_column = 'english'\n",
    "\n",
    "start = time.time()\n",
    "with open(input_file, 'r') as f:\n",
    "    tweets = [d[content_column] for d in csv.DictReader(f)]\n",
    "end = time.time()\n",
    "print(f\"Loading {len(tweets)} tweets tooks {end - start} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520103f-ab84-4377-a9b6-3abfc672e541",
   "metadata": {},
   "source": [
    "##### Load choices and extra body dictionary with structured_outputs options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f58bf-989d-4d6d-a3d7-a85ee450e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_file = \"/pbs/throng/training/universite-hiver/wschooloptim/resinwinterschool/multiple.txt\"\n",
    "with open(choices_file, 'r') as f:\n",
    "    choice = f.read().split(\"\\n\")\n",
    "\n",
    "extra_body = {\"structured_outputs\": {\"choice\": choice}}\n",
    "\n",
    "print(extra_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b6168-755b-4d74-84cc-e831b7598580",
   "metadata": {},
   "source": [
    "##### Load instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc5f4fa-799b-4a0e-8e29-975daf315826",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_file = \"/pbs/throng/training/universite-hiver/wschooloptim/resinwinterschool/instructions.txt\"\n",
    "with open(instructions_file, 'r') as f:\n",
    "    instructions = f.read()\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291f345-d9a1-4651-b0dc-72836f48a4cb",
   "metadata": {},
   "source": [
    "##### Create vllm openai client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628a66e-7d35-48c3-b832-1e09e5ed8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\", # this is the same HOST given at ollama server launching\n",
    "    api_key=\"EMPTY\"  # required but unused\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71354908-8b3a-4930-8b82-718d5a2a262f",
   "metadata": {},
   "source": [
    "##### Create async functions to asynchronously request llm server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43adab-3154-48b2-89dd-0feffd5715e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def inputsIterator(start, end):\n",
    "    for tweet in tweets[start:end]:\n",
    "        yield tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db16264-610d-4459-b6a4-3c81a1db1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def doCompletetion(tweet):\n",
    "    return client.chat.completions.create(\n",
    "        model=client.models.list().data[0].id,\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': Template(instructions).substitute(tweet=tweet)\n",
    "        }],\n",
    "        extra_body=extra_body,\n",
    "        max_completion_tokens=16,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874e646-bc18-41cb-a2cb-8146cbd0f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_all(start, end):\n",
    "    # Asynchronously call the function for each prompt\n",
    "    tasks = [\n",
    "        doCompletetion(tweet)\n",
    "        async for tweet in inputsIterator(start, end)\n",
    "    ]\n",
    "    # Gather and run the tasks concurrently\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4250237-a5aa-4383-8c89-58d5fd048b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all courutines\n",
    "init_idx = 3449\n",
    "nb_tweets = 100\n",
    "\n",
    "start = time.time()\n",
    "results = asyncio.run(run_all(start=init_idx, end=init_idx + nb_tweets))\n",
    "elapsed = time.time() - start\n",
    "\n",
    "whole_db_nb_tweets = int(1e6)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Annotationg {nb_tweets} tweets took {elapsed} seconds,\n",
    "this is {elapsed / nb_tweets} seconds per tweet or\n",
    "{(1 / (24 * 3600)) * whole_db_nb_tweets * elapsed / nb_tweets} days for the whole database of {whole_db_nb_tweets} inputs.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74b44e-079f-4246-8d8c-779f9b3e0a2a",
   "metadata": {},
   "source": [
    "> Annotationg 500 tweets took 27.607022047042847 seconds,\n",
    ">\n",
    "> tthis is 0.055214044094085694 seconds per tweet or\n",
    ">\n",
    "> 0.6670885399377953 days for the whole database of 1043873 inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed6c5f-852f-4105-b3aa-adf8d1b24f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081726f3-031b-48dc-9a0b-e21847899a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet, answer in zip(tweets, [r.choices[0].message.content for r in results]):\n",
    "    if answer == \"Jara\":\n",
    "        print(\"-----------------------------------------------\" + \"\\n\" + tweet + \"\\n\" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c90e7-3121-44fe-896d-bf8b41a41816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 (vllm)",
   "language": "python",
   "name": "vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
